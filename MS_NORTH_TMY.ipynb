{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='orange'><center>Typical Meteorological Year Creation for the North of the Mediterranean Sea</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Case Study Location: North of Mediterranean Sea|\n",
    "|-----------------------------|\n",
    "|<p align='left'>**Period:** 2000 : 2015</p>|  \n",
    "|<p align='left'>__Time step:__ 1 hour</p>|\n",
    "|<p align='left'>**Points:** 60</p>|\n",
    "|<p align='left'>**Latitude:** 40.5 : 43</p>|\n",
    "|<p align='left'>__Longitude:__ 3.5 : 8</p>|\n",
    "|<p align='left'>__Spatial step:__ 0.5ยบ</p>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'> Reading files and initiating variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where to find the initial time series files\n",
    "path = r'C:\\Users\\Cris\\Documents\\Projects\\Time series MERRA 2\\MEDITERRANEAN SEA NORTH' # use your path\n",
    "\n",
    "# Defining all files that must be retrieved\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# Path used to store the files with the Weighted Sum for each geographical location\n",
    "path2 = r'C:\\Users\\Cris\\Documents\\Projects\\Energy_resource\\Mediterranean_Sea' + \\\n",
    "r'\\Mediterranean_Sea_North\\NORTH_WS_each_point'\n",
    "\n",
    "# Creating an empty list for the files that are going to be analysed\n",
    "li = []\n",
    "\n",
    "# Iterating between the .csv files and appending each one to the empty list\n",
    "for filename in all_files:\n",
    "    frame = pd.read_csv(filename, skiprows=25, delimiter=';', index_col=None, header=None)\n",
    "    li.append(frame)\n",
    "\n",
    "# Initializing a variable for the total Weighted Sum, considering all geographical locations\n",
    "W_total = 0\n",
    "TMY_values_list = []\n",
    "\n",
    "# Opening a text file in which the best Typical Meteorological Year for each geographical location will be inserted\n",
    "f = open('Typical_Meteorological_Year_MS_North.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'> Process of Cleaning the dataframe and calculating the Weighted Sum for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating a loop for iterating between all geographycal locations\n",
    "for z in range (len(li)):\n",
    "    # Reading the CSV file and transforming into a dataframe\n",
    "    df = pd.DataFrame(li[z], index=None, columns=None)\n",
    "\n",
    "    # Creating a header list\n",
    "    Header = ['Date', 'UT time', 'Temperature', 'Relative Humidity', 'Pressure', 'Wind Speed', 'Wind Direction', 'Rainfall', \n",
    "             'Snowfall', 'Snow depth', 'Short-wave irradiation']\n",
    "\n",
    "    # Associating the header elements to each column\n",
    "    df.columns = Header \n",
    "\n",
    "    # Removing the unnecessary columns\n",
    "    df.drop(['UT time', 'Temperature', 'Relative Humidity', 'Pressure', 'Wind Direction', 'Rainfall', 'Snowfall', \n",
    "         'Snow depth'], axis=1, inplace=True)\n",
    "\n",
    "    df['Day'] = pd.DatetimeIndex(df['Date']).day # Creating a column with the days\n",
    "    df['Month'] = pd.DatetimeIndex(df['Date']).month # Creating a column with the months\n",
    "    df['Year'] = pd.DatetimeIndex(df['Date']).year # Creating a column with the years\n",
    "\n",
    "    # Rearranging the columns, so the the newly created ones appears first\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[-2:-1] + cols[-3:-2] + cols[:-3]\n",
    "    df = df.loc[:, cols]\n",
    "\n",
    "    # Dropping the 'Date' column\n",
    "    df.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "    df.drop(df.index[df['Year'] == 2015], axis=0, inplace=True) # Dropping the rows related to the single day of January 2015\n",
    "    df['Short-wave irradiation'] = df['Short-wave irradiation']/1000 # Converting the wh values into kwh\n",
    "\n",
    "    # Creating a list of the months\n",
    "    months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', \n",
    "              'November', 'December']\n",
    "\n",
    "    years = df.Year.unique() # Creating a list of the years\n",
    "    parameters = ['Short-wave irradiation', 'Wind Speed', 'Wind Speed'] # Base parameters for the analysis\n",
    "\n",
    "    size = len(years) * len(months)\n",
    "    LT_y = [] # Initiating the long-term list\n",
    "    month_y = [] # Initiating the list which will contain data from each month in each year\n",
    "    FS_list = [] # Initiating the list for the FS factor\n",
    "\n",
    "    for j in range(len(parameters)):\n",
    "        if j == 0: # Solar irradiation\n",
    "            df1 = df.groupby(['Year', 'Month', 'Day'], as_index=False).sum() # Grouping the dataframe for the GHI\n",
    "        elif j == 1: # Mean wind velocity\n",
    "            df1 = df.groupby(['Year', 'Month', 'Day'], as_index=False).mean() # Grouping for the mean wind speed parameter\n",
    "        else: # Maximum wind velocity\n",
    "            df1 = df.groupby(['Year', 'Month', 'Day'], as_index=False).max() # Grouping for the daily max wind speed parameter\n",
    "        \n",
    "        for i in range (len(months)):\n",
    "            xindex = df1.loc[df1['Month'] == i + 1] # Long-term value for each month\n",
    "            x = np.sort(xindex[parameters[j]].values) # Sorting the values for the key column to be analysed\n",
    "            y = (np.cumsum(x)-min(np.cumsum(x)))/(max(np.cumsum(x))-min(np.cumsum(x))) # Cumulative distribution for long-term\n",
    "            LT_y.append(y)\n",
    "\n",
    "            for year in years: # Loop for each month in each year\n",
    "                xindex1 = xindex.loc[df1['Year'] == year]\n",
    "                x1 = np.sort(xindex1[parameters[j]].values)\n",
    "                y1 = (np.cumsum(x1)-min(np.cumsum(x1)))/(max(np.cumsum(x1))-min(np.cumsum(x1))) \n",
    "                month_y.append(y1)\n",
    "\n",
    "                n = len(x1) # Number of days\n",
    "                delta_updated = 0\n",
    "\n",
    "                # Loop for finding the value y(x) equivalent for long-term and short-term and comparing both\n",
    "                for position,value in enumerate(x1): \n",
    "                    inx = np.where(x == value)\n",
    "                    delta = abs(y1[position] - y[inx])\n",
    "                    delta_updated += delta[0]\n",
    "                FS = delta_updated / n\n",
    "                FS_list.append(FS) # Finkelstein-Schafer (FS) statistics\n",
    "\n",
    "    LT_y_array = np.array(LT_y).reshape(len(parameters), len(months)) # columns=months, rows=parameters\n",
    "    month_y_array = np.array(month_y) # 15 years, 12 months, 3 parameters\n",
    "\n",
    "    # Arrays with the FS factor for each evaluation parameter\n",
    "    FS_matrix_sum = np.array(FS_list[:size]).reshape(len(months),len(years)).transpose()\n",
    "    FS_matrix_mean = np.array(FS_list[size:(size * 2)]).reshape(len(months),len(years)).transpose()\n",
    "    FS_matrix_max = np.array(FS_list[(size * 2):]).reshape(len(months),len(years)).transpose()\n",
    "\n",
    "    # Creating dataframes from the arrays\n",
    "    df_FS_sum = pd.DataFrame(data=FS_matrix_sum, index=years, columns=months)\n",
    "    df_FS_mean = pd.DataFrame(data=FS_matrix_mean, index=years, columns=months)\n",
    "    df_FS_max = pd.DataFrame(data=FS_matrix_max, index=years, columns=months)\n",
    "\n",
    "    # Weight factor for each evaluation parameter\n",
    "    w_sum = 0.5\n",
    "    w_mean = 0.25\n",
    "    w_max = 0.25\n",
    "\n",
    "    # Creating a matrix with the weighted sum, converting it to a dataframe and saving into a .csv file\n",
    "    WS_matrix = w_sum * FS_matrix_sum + w_mean * FS_matrix_mean + w_max * FS_matrix_max # Weighted dataframe\n",
    "    WS_df = pd.DataFrame(data=WS_matrix, index=years, columns=months)\n",
    "    WS_df.to_csv(os.path.join(path2, r'North_WS_point_{}.csv'.format(z+1)), header=True)\n",
    "    \n",
    "    # Defining the Typical Meteorological Year (TMY) for each point\n",
    "    TMY_array = np.zeros((1, len(months))) # Best months for the TMY\n",
    "    for i in range(len(months)):\n",
    "        Tm = WS_df.iloc[:, i].idxmin()\n",
    "        TMY_array[0, i] = Tm\n",
    "    TMY_list = TMY_array[0]\n",
    "    TMY_best_i = dict(zip(months, TMY_list))\n",
    "    TMY_values_list.append(TMY_list)\n",
    "    \n",
    "    # Writing the dictionary composed of the best Typical Meteorological Year for each location in a text file\n",
    "    f.write('Point {}:\\n'.format(z + 1))\n",
    "    f.write(str(TMY_best_i) + '\\n\\n')\n",
    "\n",
    "    # Updating the WS total value by adding up the WS for each point\n",
    "    W_total = W_total + WS_df\n",
    "\n",
    "# Saving the global weighted sum dataframe into a .csv file\n",
    "W_total.to_csv(os.path.join(path2, r'NORTH_W_total.csv'), header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'> Obtaining the compiled TMY based on a combination of all locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Typical Meteorological Year (TMY)\n",
    "TMY_array_best = np.zeros((1, len(months))) # Best months for the TMY\n",
    "for i in range(len(months)):\n",
    "    Tmonth = W_total.iloc[:, i].idxmin()\n",
    "    TMY_array_best[0, i] = Tmonth\n",
    "TMY_list_best = TMY_array_best[0]\n",
    "TMY_best = dict(zip(months, TMY_list_best))\n",
    "TMY_values_list.append(TMY_list_best)\n",
    "\n",
    "# Creating a dataframe with the TMY for each location and the global one\n",
    "TMY_df = pd.DataFrame(TMY_values_list, columns=months)\n",
    "# Saving the TMY dataframe to a .csv file\n",
    "TMY_df.to_csv('TMY_north.csv', header=True)\n",
    "\n",
    "# Adding to the already opened .txt file the global TMY and closing the file at the end\n",
    "f.write('General TMY:\\n')\n",
    "f.write(str(TMY_best))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
